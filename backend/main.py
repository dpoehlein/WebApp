from fastapi import FastAPI, HTTPException, UploadFile, File, Request
from backend.database import students_collection, progress_collection, assignment_grades_collection
from backend.models import Student, Progress
from bson import ObjectId

from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
from openai import OpenAI  # ‚úÖ Correct for SDK v1.x
import os
import json
import traceback
from typing import List, Optional
import importlib.util
from datetime import datetime

# ‚úÖ Load environment variables
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
if api_key:
    print("‚úÖ Loaded OpenAI Key:", api_key[:10] + "...")
else:
    print("‚ùå OPENAI_API_KEY not found!")

# ‚úÖ Initialize OpenAI client
client = OpenAI(api_key=api_key)

# ‚úÖ Load AI prompts
file_path = os.path.join(os.path.dirname(__file__), "data", "ai_prompts.json")
with open(file_path, "r", encoding="utf-8") as f:
    SUBTOPIC_AI_PROMPTS = json.load(f)

# ‚úÖ Init FastAPI
app = FastAPI()

# ‚úÖ CORS setup
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Health check
@app.get("/")
async def root():
    return {"status": "ok", "message": "FastAPI backend is running"}

# ‚úÖ Models
class ChatRequest(BaseModel):
    message: str
    topic_id: str = "general"
    subtopic_id: Optional[str] = None
    history: list[dict] = []
    objectives: Optional[List[str]] = []

# ‚úÖ Student API
@app.post("/students/")
async def create_student(student: Student):
    existing = await students_collection.find_one({"email": student.email})
    if existing:
        raise HTTPException(status_code=400, detail="Student already exists")
    result = await students_collection.insert_one(student.dict())
    return {"message": "Student added", "student_id": str(result.inserted_id)}

@app.get("/progress/{student_id}")
async def get_progress(student_id: str):
    progress = await progress_collection.find_one({"student_id": student_id})
    if not progress:
        raise HTTPException(status_code=404, detail="No progress found")
    return progress

@app.post("/progress/")
async def update_progress(progress: Progress):
    await progress_collection.update_one(
        {"student_id": progress.student_id},
        {"$set": progress.dict()},
        upsert=True
    )
    return {"message": "Progress updated"}

@app.get("/grades/{student_id}")
async def get_grades(student_id: str):
    grades = assignment_grades_collection.find({"student_id": student_id})
    results = []
    async for grade in grades:
        grade["_id"] = str(grade["_id"])
        results.append(grade)
    return results

# ‚úÖ Chat evaluator loader
def load_objective_checker(topic_id: str, subtopic_id: Optional[str]):
    if not subtopic_id:
        return None
    path = f"backend/learning_objectives/{topic_id}/{subtopic_id}.py"
    abs_path = os.path.join(os.path.dirname(__file__), path)
    if not os.path.exists(abs_path):
        print(f"‚ö†Ô∏è No custom evaluator at {path}")
        return None
    try:
        spec = importlib.util.spec_from_file_location("objectives", abs_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        return getattr(module, "get_objective_state", None)
    except Exception as e:
        print(f"‚ùå Error loading evaluator: {e}")
        return None

# ‚úÖ AI Chat endpoint
@app.post("/chat")
async def chat(request: ChatRequest):
    try:
        prompts = SUBTOPIC_AI_PROMPTS.get(request.subtopic_id or request.topic_id, SUBTOPIC_AI_PROMPTS["general"])
        system_message = prompts["system"]

        if request.objectives:
            objectives_list = "\n".join([f"- {obj}" for obj in request.objectives])
            system_message += f"\n\nThe student is working toward:\n{objectives_list}"

        system_message += "\n\nImportant: Ask only ONE question at a time."

        messages = [{"role": "system", "content": system_message}]
        if not request.history:
            messages.append({"role": "assistant", "content": prompts["initial"]})
        else:
            messages.extend(request.history)
            messages.append({"role": "user", "content": request.message})

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        )

        reply = response.choices[0].message.content
        print("ü§ñ AI Reply:", reply)

        progress_flags = []
        if request.objectives:
            custom_checker = load_objective_checker(request.topic_id, request.subtopic_id)
            if custom_checker:
                try:
                    raw_flags = custom_checker(
                        request.history + [{"role": "user", "content": request.message}, {"role": "assistant", "content": reply}]
                    )
                    progress_flags = [
                        True if flag is True else "partial" if flag else False
                        for flag in raw_flags
                    ]
                except Exception as e:
                    print("‚ö†Ô∏è Objective checker error:", e)
                    progress_flags = [False] * len(request.objectives)
            else:
                eval_prompt = (
                    "You are a tutor AI. The student is trying to complete these objectives:\n"
                    + "\n".join([f"{i+1}. {obj}" for i, obj in enumerate(request.objectives)])
                    + "\n\nBased ONLY on the last exchange, evaluate their understanding.\nReturn a list like:\n[true, \"partial\", false]"
                )

                eval_response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": eval_prompt},
                        {"role": "user", "content": request.message},
                        {"role": "assistant", "content": reply}
                    ],
                    temperature=0.0,
                    max_tokens=200
                )

                raw = eval_response.choices[0].message.content.strip()
                print("üìä Eval:", raw)

                try:
                    parsed = json.loads(raw.replace("'", '"'))
                    progress_flags = parsed if isinstance(parsed, list) else [False] * len(request.objectives)
                except Exception as e:
                    print("‚ö†Ô∏è Failed to parse eval:", e)
                    progress_flags = [False] * len(request.objectives)

        # ‚úÖ Detect if student is ready to take quiz
        ready_prompt = None
        if progress_flags:
            total = len(progress_flags)
            complete = sum(1 for p in progress_flags if p is True)
            if total > 0 and complete / total >= 0.8:
                ready_prompt = "üéØ It looks like you've mastered most of this topic. Ready to test yourself? Go ahead and take the quiz when you're ready!"

        return {
            "reply": reply,
            "progress": progress_flags,
            "ready_prompt": ready_prompt
        }

    except Exception as e:
        print("‚ö†Ô∏è Chat error:", traceback.format_exc())
        return {"reply": f"‚ö†Ô∏è Error: {str(e)}", "progress": [], "ready_prompt": None}

# ‚úÖ Binary quiz endpoint
@app.get("/quiz/binary")
async def get_binary_quiz():
    try:
        from backend.quiz.binary_quiz import generate_binary_quiz
        return {"quiz": generate_binary_quiz()}
    except Exception as e:
        print("‚ö†Ô∏è Failed to generate quiz:", e)
        raise HTTPException(status_code=500, detail="Quiz generation error")

# ‚úÖ Dynamic grading endpoint
@app.post("/grade/{topic_id}/{subtopic_id}")
async def dynamic_grader(
    topic_id: str,
    subtopic_id: str,
    file: UploadFile = File(...),
    request: Request = None
):
    try:
        contents = await file.read()
        rel_path = f"backend/graders/{topic_id}/{subtopic_id}.py"
        abs_path = os.path.join(os.path.dirname(__file__), rel_path)

        if not os.path.exists(abs_path):
            raise HTTPException(status_code=404, detail=f"No grader for {topic_id}/{subtopic_id}")

        spec = importlib.util.spec_from_file_location("grader", abs_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        if not hasattr(module, "grade"):
            raise HTTPException(status_code=500, detail=f"'grade' function missing in {topic_id}/{subtopic_id}.py")

        result = module.grade(contents)

        # ‚úÖ Save grade to MongoDB if student_id is passed
        student_id = request.query_params.get("student_id")
        if student_id:
            await assignment_grades_collection.update_one(
                {
                    "student_id": student_id,
                    "topic_id": topic_id,
                    "subtopic_id": subtopic_id
                },
                {
                    "$set": {
                        "score": result["score"],
                        "feedback": result["feedback"],
                        "timestamp": datetime.utcnow()
                    }
                },
                upsert=True
            )

        return result

    except Exception as e:
        print("‚ö†Ô∏è Grading error:", traceback.format_exc())
        raise HTTPException(status_code=500, detail="Failed to grade assignment")
